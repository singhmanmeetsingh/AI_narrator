{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14b1aa8-d19e-4d67-a998-30116d07c5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video duration: 42 seconds.\n",
      "Word Count: 105.0\n",
      "Frame extraction complete. 22 frames extracted.\n",
      "extracted_frames ['extracted_frames/frame_0.jpg', 'extracted_frames/frame_60.jpg', 'extracted_frames/frame_120.jpg', 'extracted_frames/frame_180.jpg', 'extracted_frames/frame_240.jpg', 'extracted_frames/frame_300.jpg', 'extracted_frames/frame_360.jpg', 'extracted_frames/frame_420.jpg', 'extracted_frames/frame_480.jpg', 'extracted_frames/frame_540.jpg', 'extracted_frames/frame_600.jpg', 'extracted_frames/frame_660.jpg', 'extracted_frames/frame_720.jpg', 'extracted_frames/frame_780.jpg', 'extracted_frames/frame_840.jpg', 'extracted_frames/frame_900.jpg', 'extracted_frames/frame_960.jpg', 'extracted_frames/frame_1020.jpg', 'extracted_frames/frame_1080.jpg', 'extracted_frames/frame_1140.jpg', 'extracted_frames/frame_1200.jpg', 'extracted_frames/frame_1260.jpg']\n",
      "**[Voiceover]**\n",
      "\n",
      "\"Alright, we’re jumping into an intense moment! The score is 3-5, and time is running out. Our player is peeking around the corner, weapon ready. They spot an enemy and take a shot—headshot! That’s a crucial kill!\n",
      "\n",
      "Now, they’re moving cautiously, checking angles. The tension is palpable as they navigate through tight spaces. They hear footsteps—quickly, they adjust their aim. \n",
      "\n",
      "With only 30 seconds left, they climb up for a better vantage point. They spot another enemy, fire, and—another headshot! \n",
      "\n",
      "Time’s ticking down, and they clutch the round, tying the game! What a play!\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import base64\n",
    "import openai\n",
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def extract_frames(video_path, output_folder, frame_interval=60):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return []\n",
    "\n",
    "    frame_count = 0\n",
    "    extracted_frame_paths = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_filename = f\"{output_folder}/frame_{frame_count}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            extracted_frame_paths.append(frame_filename)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Frame extraction complete. {len(extracted_frame_paths)} frames extracted.\")\n",
    "\n",
    "    return extracted_frame_paths\n",
    "\n",
    "def get_video_duration(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Get frame rate\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Get total frame count\n",
    "\n",
    "    duration = round(frame_count / fps) if fps > 0 else 0  # Round the duration\n",
    "\n",
    "    cap.release()\n",
    "    return duration\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def get_frame_descriptions(frame_paths, final_prompt, max_retries=3, retry_delay=2):\n",
    "    base64_frames = [image_to_base64(path) for path in frame_paths]\n",
    "\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                *map(lambda x: {\"image\": x, \"resize\": 768}, base64_frames),\n",
    "                final_prompt\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = client.chat.completions.create(**params)\n",
    "            return result.choices[0].message.content\n",
    "        except openai.InternalServerError as e:\n",
    "            print(f\"Server error on attempt {attempt + 1}: {e}. Retrying after {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "\n",
    "    print(\"Failed to obtain descriptions after several retries.\")\n",
    "    return None\n",
    "\n",
    "# Main execution\n",
    "# video_path = \"video.mp4\"\n",
    "video_path = \"v2.mp4\"\n",
    "output_folder = \"extracted_frames\"\n",
    "\n",
    "# Calculate video duration and adjust prompt\n",
    "video_duration = get_video_duration(video_path)\n",
    "print(f\"Video duration: {video_duration} seconds.\")\n",
    "\n",
    "word_count = video_duration * 2.5\n",
    "print(f\"Word Count: {word_count}\")\n",
    "\n",
    "prompt = f\"(This video is ONLY {video_duration} seconds long, so make sure the voiceover MUST be less than {word_count} words)\"\n",
    "\n",
    "# final_prompt = \"ACT as an commentator. In a conversational style, explain step-by-step what is happening in match the frames suitable for a voiceover.\" + prompt\n",
    "# promt can be act as an engaging commentator\n",
    "final_prompt = \"ACT as an commentator. In a conversational style, explain step-by-step what is happening in valorant game the frames suitable for a voiceover.\" + prompt\n",
    "\n",
    "# Extract frames and get descriptions\n",
    "extracted_frames = extract_frames(video_path, output_folder)\n",
    "print(\"extracted_frames\",extracted_frames)\n",
    "descriptions = get_frame_descriptions(extracted_frames, final_prompt)\n",
    "\n",
    "print(descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c479e-1e81-4724-b2c1-ffe3f4f651c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voiceover(text, output_audio_path, model=\"tts-1\", voice=\"echo\"):\n",
    "    response = client.audio.speech.create(\n",
    "        model=model,\n",
    "        voice=voice,\n",
    "        input=text\n",
    "    )\n",
    "    response.stream_to_file(Path(output_audio_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddc818-8f16-40c7-b654-d8b1e7a932cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge audio with video\n",
    "def merge_audio_video(video_path, audio_path, output_video_path):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "\n",
    "    final_clip = video_clip.set_audio(audio_clip)\n",
    "    final_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa536f5-0988-48ca-938a-b675d44be594",
   "metadata": {},
   "outputs": [],
   "source": [
    "if extracted_frames:\n",
    "    descriptions = get_frame_descriptions(frame_paths, finalprompt)\n",
    "    print(\"Descriptions obtained from GPT Vision API:\")\n",
    "    print(descriptions)\n",
    "\n",
    "    # Create and save voiceover\n",
    "    output_audio_path = 'voiceover.mp3'\n",
    "    create_voiceover(descriptions, output_audio_path)\n",
    "\n",
    "    # Merge audio with video and save as new file\n",
    "    output_video_path = 'openai2.mp4'\n",
    "    merge_audio_video(video_path, output_audio_path, output_video_path)\n",
    "else:\n",
    "    print(\"No frames were extracted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
