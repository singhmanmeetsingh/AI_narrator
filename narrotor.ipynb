{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14b1aa8-d19e-4d67-a998-30116d07c5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video duration: 42 seconds.\n",
      "Word Count: 105.0\n",
      "Frame extraction complete. 22 frames extracted.\n",
      "extracted_frames ['extracted_frames/frame_0.jpg', 'extracted_frames/frame_60.jpg', 'extracted_frames/frame_120.jpg', 'extracted_frames/frame_180.jpg', 'extracted_frames/frame_240.jpg', 'extracted_frames/frame_300.jpg', 'extracted_frames/frame_360.jpg', 'extracted_frames/frame_420.jpg', 'extracted_frames/frame_480.jpg', 'extracted_frames/frame_540.jpg', 'extracted_frames/frame_600.jpg', 'extracted_frames/frame_660.jpg', 'extracted_frames/frame_720.jpg', 'extracted_frames/frame_780.jpg', 'extracted_frames/frame_840.jpg', 'extracted_frames/frame_900.jpg', 'extracted_frames/frame_960.jpg', 'extracted_frames/frame_1020.jpg', 'extracted_frames/frame_1080.jpg', 'extracted_frames/frame_1140.jpg', 'extracted_frames/frame_1200.jpg', 'extracted_frames/frame_1260.jpg']\n",
      "**[Voiceover]**\n",
      "\n",
      "\"Alright, we’re jumping into the action! The score is tight, 3 to 5. Our player is peeking around the corner, weapon ready. They spot an enemy and take a shot—headshot! That’s a crucial kill!\n",
      "\n",
      "Now, they’re moving strategically, checking angles. The timer’s ticking down to 40 seconds. They’re using the environment to their advantage, hiding behind cover.\n",
      "\n",
      "Oh! Another enemy sighted! Quick reflexes—another headshot! The score is now 4 to 5. \n",
      "\n",
      "With just seconds left, they make a bold move, pushing forward. It’s a clutch moment! They secure the final kill just in time. What a play! Tied game!\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import base64\n",
    "import openai\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "def extract_frames(video_path, output_folder, frame_interval=60):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return []\n",
    "\n",
    "    frame_count = 0\n",
    "    extracted_frame_paths = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_filename = f\"{output_folder}/frame_{frame_count}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            extracted_frame_paths.append(frame_filename)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Frame extraction complete. {len(extracted_frame_paths)} frames extracted.\")\n",
    "\n",
    "    return extracted_frame_paths\n",
    "\n",
    "def get_video_duration(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Get frame rate\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Get total frame count\n",
    "\n",
    "    duration = round(frame_count / fps) if fps > 0 else 0  # Round the duration\n",
    "\n",
    "    cap.release()\n",
    "    return duration\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def get_frame_descriptions(frame_paths, final_prompt, max_retries=3, retry_delay=2):\n",
    "    base64_frames = [image_to_base64(path) for path in frame_paths]\n",
    "\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                *map(lambda x: {\"image\": x, \"resize\": 768}, base64_frames),\n",
    "                final_prompt\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0  # chanege the temperature if you want more engagement\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = client.chat.completions.create(**params)\n",
    "            return result.choices[0].message.content\n",
    "        except openai.InternalServerError as e:\n",
    "            print(f\"Server error on attempt {attempt + 1}: {e}. Retrying after {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "\n",
    "    print(\"Failed to obtain descriptions after several retries.\")\n",
    "    return None\n",
    "\n",
    "# Main execution\n",
    "# video_path = \"video.mp4\"\n",
    "video_path = \"v2.mp4\"\n",
    "output_folder = \"extracted_frames\"\n",
    "\n",
    "# Calculate video duration and adjust prompt\n",
    "video_duration = get_video_duration(video_path)\n",
    "print(f\"Video duration: {video_duration} seconds.\")\n",
    "\n",
    "word_count = video_duration * 2.5  # change it to 2 if you see the timings don;t match\n",
    "print(f\"Word Count: {word_count}\")\n",
    "\n",
    "prompt = f\"(This video is ONLY {video_duration} seconds long, so make sure the voiceover MUST be less than {word_count} words)\"\n",
    "\n",
    "# final_prompt = \"ACT as an commentator. In a conversational style, explain step-by-step what is happening in match the frames suitable for a voiceover.\" + prompt\n",
    "# promt can be act as an engaging commentator\n",
    "final_prompt = \"ACT as an commentator. In a conversational style, explain step-by-step what is happening in valorant game the frames suitable for a voiceover.\" + prompt\n",
    "\n",
    "# Extract frames and get descriptions\n",
    "extracted_frames = extract_frames(video_path, output_folder)\n",
    "print(\"extracted_frames\",extracted_frames)\n",
    "descriptions = get_frame_descriptions(extracted_frames, final_prompt)\n",
    "\n",
    "print(descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67c479e-1e81-4724-b2c1-ffe3f4f651c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voiceover(text, output_audio_path, model=\"tts-1\", voice=\"echo\"):\n",
    "    response = client.audio.speech.create(\n",
    "        model=model,\n",
    "        voice=voice,\n",
    "        input=text\n",
    "    )\n",
    "    response.stream_to_file(Path(output_audio_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ddc818-8f16-40c7-b654-d8b1e7a932cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "# Function to merge audio with video\n",
    "def merge_audio_video(video_path, audio_path, output_video_path):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "\n",
    "    final_clip = video_clip.set_audio(audio_clip)\n",
    "    final_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa536f5-0988-48ca-938a-b675d44be594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video openai2.mp4.\n",
      "MoviePy - Writing audio in openai2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video openai2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready openai2.mp4\n"
     ]
    }
   ],
   "source": [
    "if extracted_frames:\n",
    "    # Create and save voiceover\n",
    "    output_audio_path = 'voiceover.mp3'\n",
    "    create_voiceover(descriptions, output_audio_path)\n",
    "\n",
    "    # Merge audio with video and save as new file\n",
    "    output_video_path = 'openai2.mp4'\n",
    "    merge_audio_video(video_path, output_audio_path, output_video_path)\n",
    "else:\n",
    "    print(\"No frames were extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f28d1-902a-4207-a18e-c54a19a63340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
